最新の GPT 系列モデル（「GPT-4o」「GPT-4o-mini」「o1-mini」）を使用するコード例を示します。
開発時の参考ドキュメントとしてご利用ください。

## 前提条件
1. `openai` ライブラリがインストールされていること

   ```bash
   pip install openai

	2.	OpenAI の API キーを取得し、環境変数 OPENAI_API_KEY に設定していること

共通設定

import openai
import os

# OpenAI API キーの設定
openai.api_key = os.getenv("OPENAI_API_KEY")

# モデルに送信するプロンプト
prompt = "最新のAI技術動向について教えてください。"

1. GPT-4o を使用する場合

response = openai.ChatCompletion.create(
    model="gpt-4o",
    messages=[
        {"role": "user", "content": prompt}
    ]
)

print(response['choices'][0]['message']['content'])

2. GPT-4o-mini を使用する場合

response = openai.ChatCompletion.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": prompt}
    ]
)

print(response['choices'][0]['message']['content'])

3. o1-mini を使用する場合

response = openai.ChatCompletion.create(
    model="o1-mini",
    messages=[
        {"role": "user", "content": prompt}
    ]
)

print(response['choices'][0]['message']['content'])

注意点
	•	各モデルの利用には、対応する API アクセス権限が必要です。
	•	最新の情報や詳細については、OpenAI の公式ドキュメント をご参照ください。

これらのサンプルコードを参考に、目的に応じて適切なモデルを選択し、OpenAI API を活用してください。


-------------------------------------------------------------

DeepSeek APIは、OpenAIと互換性のあるAPIフォーマットを採用しています。そのため、設定を変更することで、OpenAIのSDKやOpenAI APIと互換性のあるソフトウェアを使用してDeepSeek APIにアクセスできます。

**基本設定:**

- `base_url`: `https://api.deepseek.com`
- `api_key`: [APIキーの取得](https://platform.deepseek.com/api_keys)

互換性のために、`base_url`を`https://api.deepseek.com/v1`に設定することも可能ですが、ここでの`v1`はモデルのバージョンとは関係ありません。

**モデルの指定:**

- `deepseek-chat`モデルはDeepSeek-V3にアップグレードされました。APIの使用方法は変更されておらず、`model='deepseek-chat'`と指定することでDeepSeek-V3を呼び出せます。

**チャットAPIの呼び出し方法:**

APIキーを取得した後、以下のサンプルスクリプトを使用してDeepSeek APIにアクセスできます。これは非ストリーミングの例であり、`stream`パラメータを`true`に設定することでストリーミング応答を受け取ることも可能です。

**Pythonの例:**

```python
from openai import OpenAI

client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    stream=False
)

print(response.choices[0].message.content)
```

**JSON出力機能:**

DeepSeekは、モデルが有効なJSON文字列を出力するためのJSON出力機能を提供しています。この機能を有効にするには、`response_format`パラメータを`{'type': 'json_object'}`に設定し、システムまたはユーザープロンプトに「json」という単語を含め、望ましいJSON形式の例を提供してモデルが正しいJSONを出力できるようにします。

**Pythonの例:**

```python
import json
from openai import OpenAI

client = OpenAI(api_key="<your api key>", base_url="https://api.deepseek.com")

system_prompt = """
The user will provide some exam text. Please parse the "question" and "answer" and output them in JSON format.
EXAMPLE INPUT:
Which is the highest mountain in the world? Mount Everest.
EXAMPLE JSON OUTPUT:
{
  "question": "Which is the highest mountain in the world?",
  "answer": "Mount Everest"
}
"""

user_prompt = "Which is the longest river in the world? The Nile River."
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_prompt}
]

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=messages,
    response_format={'type': 'json_object'}
)

print(json.loads(response.choices[0].message.content))
```

**FIM補完機能 (ベータ版):**

FIM（Fill In the Middle）補完では、ユーザーがプレフィックスとサフィックス（オプション）を提供し、モデルがその間の内容を補完します。この機能は、コンテンツ補完やコード補完によく使用されます。FIM補完を使用するには、`base_url`を`https://api.deepseek.com/beta`に設定してベータ機能を有効にします。

**Pythonの例:**

```python
from openai import OpenAI

client = OpenAI(api_key="<your api key>", base_url="https://api.deepseek.com/beta")

response = client.completions.create(
    model="deepseek-chat",
    prompt="def fib(a):",
    suffix="    return fib(a-1) + fib(a-2)",
    max_tokens=128
)

print(response.choices[0].text)
```

**Function Calling機能:**

Function Callingを使用すると、モデルが外部ツールを呼び出してその機能を拡張できます。現在の`deepseek-chat`モデルのFunction Calling機能は不安定であり、ループ呼び出しや空の応答が発生する可能性があります。この問題は次のバージョンで解決予定です。

**Pythonの例:**

```python
from openai import OpenAI

def send_messages(messages):
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        tools=tools
    )
    return response.choices[0].message

client = OpenAI(api_key="<your api key>", base_url="https://api.deepseek.com")

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get weather of a location, the user should supply a location first",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    }
                },
                "required": ["location"]
            },
        }
    },
]

messages = [{"role": "user", "content": "How's the weather in Hangzhou?"}]
message = send_messages(messages)
print(f"User>\t  {messages[0]['content']}")
tool = message.tool_calls[0]
messages.append(message)
messages.append({"role": "tool", "tool_call_id": tool.id, "content": "24℃"})
message = send_messages(messages)
print(f"Model>\t  {message.content}")
```

**トークンとトークン使用量:**

トークンは、モデルが自然言語テキストを表現するために使用する基本単位であり、請求の単位としても使用されます。一般的に、英語の文字は約0.3トークン、中国 