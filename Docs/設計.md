# システム設計仕様書

## 1. システム概要

求人情報クローリングシステムは、指定された求人サイトから情報を自動収集し、ユーザーが効率的に求人情報を管理・応募できるようにするシステムです。

## 2. システムアーキテクチャ

### 2.1 主要コンポーネント

- **クローラーモジュール** (crawler.py)
  - Seleniumを使用したWeb情報収集
  - ヘッドレスChrome使用
  - エラーハンドリングと再試行機能

- **Webアプリケーション** (app.py)
  - Flask Webフレームワーク
  - ユーザー認証（Supabase連携）
  - 求人情報の表示・管理機能

- **一括応募処理** (bulk_apply.py)
  - 選択した求人への自動応募機能
  - 応募状況の追跡

- **決済・認証処理** (supabase_stripe_handler.py)
  - Supabase認証連携
  - Stripe決済処理
  - ユーザーサブスクリプション管理

### 2.2 データフロー

1. クローラーによるデータ収集
   - 定期的な求人情報スクレイピング
   - フィルタリング処理
   - JSONファイルへの保存

2. データ保存・管理
   - Supabaseデータベースでの永続化
   - ローカルJSONファイルでのキャッシュ
   - 重複チェックと更新処理

3. ユーザーインタラクション
   - Web UIでの求人閲覧
   - 応募管理
   - サブスクリプション管理

## 3. データ構造

### 3.1 クローリングデータ (crawled_data/)

```
crawled_data/
├── jobs_[YYYYMMDD]_[HHMMSS].json    # 生のクローリングデータ
├── jobs_[YYYYMMDD]_[HHMMSS]_filtered.json    # フィルター済みデータ
├── checked_jobs.json    # 処理済み求人リスト
└── settings.json    # クローラー設定
```

### 3.2 JSONデータ構造

```json
{
  "job_id": "string",
  "title": "string",
  "company": "string",
  "location": "string",
  "salary": "string",
  "description": "string",
  "requirements": "string",
  "url": "string",
  "crawled_at": "datetime",
  "status": "string"
}
```

## 4. 処理フロー

### 4.1 クローリング処理

1. 初期化
   - Chromeドライバーの設定
   - ログイン処理
   - 設定ファイル読み込み

2. データ収集
   - ページネーション処理
   - 要素抽出
   - エラーハンドリング

3. データ保存
   - タイムスタンプ付きJSONファイル生成
   - フィルタリング処理
   - 重複チェック

### 4.2 一括応募処理

1. 応募対象選択
2. 自動ログイン
3. 応募フォーム入力
4. 送信処理
5. 結果記録

### 4.3 ユーザー認証フロー

1. Supabase認証
2. セッション管理
3. 権限チェック

## 5. エラーハンドリング

### 5.1 クローラー

- 接続エラー: 再試行（最大3回）
- 要素未検出: スキップして続行
- セッション切れ: 再ログイン

### 5.2 アプリケーション

- 認証エラー: リダイレクト
- DB接続エラー: フォールバック処理
- API制限: レート制限対応

## 6. ログ管理

### 6.1 ログ構造

```
logs/
└── crawler.log    # クローラーの実行ログ
```

### 6.2 ログレベル

- INFO: 通常の処理状況
- WARNING: 軽微な問題
- ERROR: 重大なエラー
- DEBUG: 詳細なデバッグ情報

## 7. セキュリティ

- HTTPS通信の強制
- クレデンシャル情報の環境変数管理
- SQLインジェクション対策
- XSS対策
- CSRF対策

## 8. パフォーマンス最適化

- クローリング間隔の調整
- コネクションプーリング
- キャッシュ制御
- データベースインデックス最適化

## 9. 監視・メンテナンス

- ログモニタリング
- パフォーマンスメトリクス収集
- 定期的なデータクリーンアップ
- バックアップ処理

## 10. 拡張性・スケーラビリティ

- モジュラー設計
- 設定の外部化
- マルチプロセス対応
- キューイングシステム対応