# システム設計仕様書

## 1. システム概要

### 1.1 取得元
- **CrowdWorks**: 日本のフリーランス向け案件サイト（https://crowdworks.jp）から案件情報を取得
  - 案件ID、タイトル、予算情報、募集期限、詳細説明などの情報を収集

### 1.2 取得方法
- **Selenium WebDriver**: ヘッドレスChromeを使用した動的ページのクローリング
- **ログイン機能**: CrowdWorksアカウントでログインし会員限定コンテンツにアクセス
- **自動化検出回避**: User-Agent偽装、WebDriver検出回避のJavaScript注入
- **間隔制御**: サーバー負荷軽減のためのランダムな待機時間設定

## 2. データ処理と保存

### 2.1 収集データ項目
- 案件ID: CrowdWorks固有の識別子
- タイトル: 案件タイトル
- 予算: 案件の報酬条件
- 募集期限: 応募可能期限
- 説明文: 案件の詳細説明
- URL: 案件詳細ページへのリンク
- クローリング日時: データ取得タイムスタンプ

### 2.2 AIフィルタリング処理
- OpenAI GPTモデルまたはDeepseekモデルを使用
- ユーザー定義の条件（例：「予算が10,000以上のもののみピックする」）に基づき案件を評価
- 各案件情報をAIに送信し、条件適合性を判断（JSON形式で結果取得）

### 2.3 データ保存構造
- **生データ**: `crawled_data/jobs_[YYYYMMDD]_[HHMMSS].json`
- **フィルタリング済みデータ**: `crawled_data/jobs_[YYYYMMDD]_[HHMMSS]_filtered.json`
- **処理済み案件リスト**: `crawled_data/checked_jobs.json`（重複回避用）
- **設定ファイル**: `crawled_data/settings.json`（API鍵、フィルター設定）
- **ログファイル**: `logs/crawler.log`（実行ログ）

### 2.4 取得条件と制限
- **重複排除**: `checked_jobs.json`に記録された案件IDは再取得しない
- **取得頻度**: 1日1回の定期クローリング
- **取得上限**: 1回のクローリングで最大100件まで取得（サーバー負荷考慮）
- **ページ制限**: 最大10ページまでのページネーション処理

## 3. 一括応募機能

- フィルタリングで選択された案件に対して自動応募を実行
- Seleniumを使用したブラウザ自動操作
- CrowdWorksへの自動ログイン、案件ページアクセス、応募フォーム入力、送信処理

## 4. Webアプリケーション

### 4.1 表示機能
- **求人一覧**: フィルタリング済み案件の一覧表示
- **案件詳細**: 個別案件の詳細情報表示

### 4.2 管理機能
- **クローリング実行**: 手動でのクローリングジョブ実行
- **一括応募実行**: 選択した案件への一括応募処理

### 4.3 認証・決済
- **ユーザー認証**: Supabase認証システムによるログイン管理
- **サブスクリプション**: Stripe連携による課金管理

## 5. システムアーキテクチャ

### 5.1 主要コンポーネント

- **クローラーモジュール** (crawler.py)
  - Seleniumを使用したWeb情報収集
  - ヘッドレスChrome使用
  - エラーハンドリングと再試行機能

- **Webアプリケーション** (app.py)
  - Flask Webフレームワーク
  - ユーザー認証（Supabase連携）
  - 求人情報の表示・管理機能

- **一括応募処理** (bulk_apply.py)
  - 選択した求人への自動応募機能
  - 応募状況の追跡

- **決済・認証処理** (supabase_stripe_handler.py)
  - Supabase認証連携
  - Stripe決済処理
  - ユーザーサブスクリプション管理

### 5.2 データフロー

1. クローラーによるデータ収集
   - 定期的な求人情報スクレイピング
   - フィルタリング処理
   - JSONファイルへの保存

2. データ保存・管理
   - ローカルJSONファイルでの保存
   - 重複チェックと更新処理

3. ユーザーインタラクション
   - Web UIでの求人閲覧
   - 応募管理
   - サブスクリプション管理

## 6. エラーハンドリング

### 6.1 クローラー

- 接続エラー: 再試行（最大3回）
- 要素未検出: スキップして続行
- セッション切れ: 再ログイン

### 6.2 アプリケーション

- 認証エラー: リダイレクト
- API制限: レート制限対応

## 7. セキュリティ

- HTTPS通信の強制
- クレデンシャル情報の環境変数管理
- XSS対策